import pytest
from unittest.mock import MagicMock, patch
from pyspark.sql import DataFrame, Row
from pyspark.sql import functions as F
import datetime

# Assume the BronzeWriter class and all dependencies (AuditLogger, DeltaManager, etc.)
# are defined and available.

# The fixtures for dependencies and patching remain the same
# as provided in previous responses.

def test_ingest_files_full_success(mock_dependencies, patch_private_methods):
    """
    Tests the full successful ingestion workflow without using the mock_spark_df_chain fixture.
    """
    # 1. Instantiate the BronzeWriter class with mocked dependencies.
    bronze_writer = BronzeWriter(**mock_dependencies)

    # 2. Manually create a mock DataFrame with chainable methods.
    # This replaces the need for the mock_spark_df_chain fixture.
    mock_df = MagicMock(spec=DataFrame)
    mock_df.join.return_value = mock_df
    mock_df.filter.return_value = mock_df
    mock_df.select.return_value = mock_df
    mock_df.withColumn.return_value = mock_df
    mock_df.persist.return_value = mock_df
    mock_df.unpersist.return_value = None
    mock_df.columns = ["file_name", "_corrupt_record"]
    mock_df.isEmpty.return_value = False
    mock_df.count.return_value = 100
    mock_df.collect.return_value = [
        Row(file_path="path/to/file1.csv", file_name="file1.csv")
    ]
    
    # 3. Configure the patched private methods to return the manually created mock.
    patch_private_methods["mock_read_source"].return_value = mock_df
    patch_private_methods["mock_get_counts"].return_value = mock_df
    
    # 4. Define mock input data for the function under test.
    config_row = Row(
        catalog_name="catalog",
        schema_name="schema",
        target_table_name="target_table",
        source_folder="source_folder",
        allowed_threshold=0.1
    )
    claimed_files_df = MagicMock(spec=DataFrame)
    claimed_files_df.select.return_value.collect.return_value = [
        Row(file_path="path/to/file1.csv")
    ]
    
    # 5. Configure specific return values for the test scenario.
    mock_df.isEmpty.side_effect = [False, True]  # files_to_process not empty, files_to_reject empty
    mock_dependencies["delta_manager"].append_df_to_table.return_value = {"file1.csv": 100}

    # 6. Act: Call the function.
    bronze_writer.ingest_files(config_row, claimed_files_df)

    # 7. Assertions: Verify the entire workflow was executed as expected.
    patch_private_methods["mock_read_source"].assert_called_once()
    patch_private_methods["mock_get_counts"].assert_called_once()
    mock_df.persist.assert_called_once()
    mock_df.count.assert_called_once()
    mock_df.unpersist.assert_called_once()
    mock_dependencies["data_processor"].trim_all_string_columns.assert_called_once()
    mock_dependencies["delta_manager"].append_df_to_table.assert_called_once()
    mock_dependencies["delta_manager"].set_table_properties.assert_called_once()
    mock_dependencies["logger"].log_file_status.assert_called_once_with(
        mock_df.collect()[0],
        "(mock_catalog).(mock_schema).target_table",
        "test_run_id",
        patch_private_methods["mock_get_datetime"].return_value,
        "Success",
        succeeded=100
    )
    patch_private_methods["mock_finalize_status"].assert_called_once()
